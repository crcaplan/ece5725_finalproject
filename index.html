
<!DOCTYPE html>
<!-- saved from url=(0048)https://crcaplan.github.io/ece5725_finalproject/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>ECE 5725: Touchless Music Player</title>

    <!-- Bootstrap core CSS -->
    <link href="./ECE 5725_ Touchless Music Player_files/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="./ECE 5725_ Touchless Music Player_files/starter-template.css" rel="stylesheet">

  </head>

  <body style="background-color:whitesmoke;" data-new-gr-c-s-check-loaded="14.1012.0" data-gr-ext-installed="" data-new-gr-c-s-loaded="14.1012.0">

    <nav class="navbar navbar-inverse navbar-fixed-top" style="background-color: #0a6194">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="https://crcaplan.github.io/ece5725_finalproject/#">Touchless Music Player</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#">Home</a></li>
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#obj">Objective</a></li>
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#intro">Introduction</a></li>
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#design">Design &amp; Testing</a></li>
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#results">Results</a></li>
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#future">Future Works</a></li>
            <li><a href="https://crcaplan.github.io/ece5725_finalproject/#conclusion">Conclusion</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="starter-template">
        <h1>Touchless Music Player</h1>
        <p class="lead">ECE 5725 Project<br>Tamzid Ahmed (ta326) and Claire Caplan (crc235)<br>05/19/2021</p>
      </div>

      <hr>
      <div class="center-block">
          <h2 style="text-align:center;">Demonstration Video</h2>
          <iframe width="640" height="360" src="https://www.cornell.edu/video/glorious-to-view" frameborder="0" allowfullscreen=""></iframe>
      </div>

    <hr id="obj">
    <div style="text-align:center;">
        <h2>Objective</h2>
        <p style="text-align: left;padding: 0px 30px;">Touchless music player uses a Raspberry Pi to function as a jukebox by allowing users to make their own personalized playlist and select a song to be played from the playlist on a speaker connected to the Raspberry Pi. Each user has their own QR code that they need to scan so that their playlist can be displayed on piTFT from which they can select the song that they want to play through hand gestures</p>
    <br>
        <img class="img-rounded" src="https://crcaplan.github.io/ece5725_finalproject/" alt="picture of the 3d structure" style="width:30%;">
    <br>
Figure 1: Finished “Touchless Music Player” prototype

    </div>

    <hr id="intro">
    <div style="text-align:center;">
      <h2>Introduction</h2>
      <p style="text-align: left;padding: 0px 30px;"> The project started with installing opencv and required libraries on Raspberry Pi. We installed piCamera and integrated it with openCV to detect QR code when the user holds the QRcode in front of the camera. We wrote a python script to detect the QRcode using openCV and qrcode library from python. Next we collected all the required parts needed for the hand gesture recognition circuit. We used Adafruit break beam sensors for song selection, play/pause and an ultrasonic sensor to control the volume. The explanation of how the circuit works will be explained in the design section. Once we made a schematic for the hand gesture and checked the correctness of the circuit with the TAs we tested the circuit by checking the piscope signal and writing python scripts and checking the outputs in the terminal. After that we wrote a script to control song selection using IR sensors and volume control using ultrasonic sensors. Once the song selection was working, we had to integrate the QR scanning with song selection so that once the users scan their QR code, they can play music using hand gestures. We also added an option for a new user to receive a QR code and select the songs that they want to be in their playlist. Once all the programming was done, we also made a 3D printed structure to hold the whole music system. Our device, as well as both team members, can be seen in Figure 1 below. </p>
    </div>
    <!--
    <div style="text-align:center;">
            <h2>Introduction</h2>
            <h4 style="text-align: left;text-indent: 0.8cm">Motivation: </h4>
            <p style="text-align: left;padding: 0px 30px;">We are first inspired on how drones are able to track the user as they record a video, providing a convenient experience for the user. We then thought about having a ground robot that has a similar tracking capability, where it will be able to carry things around and also operate indoors. The user will be able to seamlessly interact with the robot using finger gestures. This robot can be installed on shopping carts in grocery stores or luggage carts in the airport. Having this robot will allow the user to conserve their energy (from carrying items or pushing carts) and also focus their attention on other things, such as looking for the things they wanted to get from the grocery racks.</p>
            <h4 style="text-align: left;text-indent: 0.8cm">Solution: </h4>
            <p style="text-align: left;padding: 0px 30px;">A robot is designed to be able to track and follow a ball (representing a human), as well as to read hand-gesture inputs from the user. Computer Vision is utilized to process the video input the camera to detect for the ball and hand gestures. PID controller mechanism is used for the robot motor for smooth tracking.</p>
    </div>
    -->
    

    <hr id="design">

      <div style="text-align:center;">
        <h2>Design and Testing</h2>             
        <h4 style="text-align: left;text-indent: 0.8cm">QR Code Detection:</h4>
        <p style="text-align: left;padding: 0px 30px;"> We began our project by first installing OpenCV on the Raspberry Pi. Following the instructions provided on Canvas, we were able to install OpenCV for Python3. Using a camera installation reference video from the Raspberry Pi official channel, we installed the PiCamera on the Raspberry Pi. Next we used the provided Canvas example on OpenCV to learn how to use OpenCV and to install the required libraries needed for OpenCV and QR code scanners [1]. Following the instructions in [1], we were able to write a python script qr_scanner.py that can scan a QR code using the PiCamera and show the message embedded in the QR code on the PiCamera window and the terminal. We tested the script by checking if the previously generated QR codes can be detected and if the message embedded in the QR code can be read by the camera. Once the script reads the data from the QR code, it checks if the username already exists in a text file called netid.txt where we stored all known users in the system. We also integrated the QR scanner code with pygame to instruct the user to begin the scan and show on the Pygame GUI if the scan succeeded. Figure 2 below shows some pictures of the pygame window for showing how the scan works. </p>
        <br>
        <p> All the testing early in the project development was done on the desktop, where the Pygame GUI and camera feed were in two separate windows like in Figure 3 below. </p>
        <br>
        <img class="img-rounded" src="https://crcaplan.github.io/ece5725_finalproject/" alt="Desktop testing of camera scanner code" style="width:30%;">
        <br>
     Figure 2: Desktop testing of camera scanner code
       <p>We wanted our project to be deployed on a standalone Raspberry Pi and thus we needed the camera window to show up on the PiTFT display. Initially we could not get the camera window to show up on the PiTFT display as our program would just hang and the PiTFT would not respond to any further inputs. After following references from the Air Canvas project from Fall 2019 we were able to make the camera window show up on PiTFT. We needed to rescale the PiCamera feed window to PiTFT screen size(320x240) and render the camera display on the Pygame window, which we implemented in a helper function, and then the camera feed showed up as expected. This is seen below in Figure 3. </p>
       <br>
       <img class="img-rounded" src="https://crcaplan.github.io/ece5725_finalproject/" alt="picture of the 3d structure" style="width:30%;">
       <br>
      Figure 3: PiTFT testing of camera scanner code
      <h4 style="text-align: left;text-indent: 0.8cm">Sensor Schematic development</h4>
      <p> Initially, we planned to use a combination of IR emitters and photodiodes to sense hand motions for play/pause control and skipping/rewinding tracks, and an ultrasonic sensor to control volume based on hand distance from the music playing unit. However, the IR emitter/photodiode pairs would have required an unnecessarily complicated hardware setup involving a tunable amplifier circuit with an op-amp and potentiometers in order to be read by the Raspberry Pi GPIO pins. At the suggestion of the professor, we elected to design our hand motion detection hardware around two emitter/receiver pairs of Adafruit break-beam sensors, which simplified this aspect of the hardware greatly and increased its reliability
The break-beam sensors come in emitter/receiver pairs. The emitter is connected to a voltage source and grounded, and emits a constant IR beam. The receiver is an IR-sensitive device, and is also connected to the same voltage source and ground, but it includes an additional signal output. When the beam “connection” is broken by a non IR-transparent object (for example, the human hand), this signal output will drop to a logic low which can be detected by a Raspberry Pi GPIO input-configured pin.
     </p>

    </div>
    <!--
    <hr id='testings'>

      <div style="text-align:center;">
              <h2>Testings</h2>
              <h4 style="text-align: left;text-indent: 0.8cm">Ball tracking system: </h4>
              <p style="text-align: left;padding: 0px 30px;">
              </p>

              <h4 style="text-align: left;text-indent: 0.8cm">Hand gesture detection: </h4>
              <p style="text-align: left;padding: 0px 30px;"> </p>

      </div>
      <div style="text-align:left;">        
        <pre><code>
            inser Generic code</code></pre>
      </div>
      <div style="text-align:center;">
              <p style="text-align: left;padding: 0px 30px;">
              </p>
              <h4 style="text-align: left;text-indent: 0.8cm">Motor Control: </h4>
              <p style="text-align: left;padding: 0px 30px;"></p>
              <br> Several images describing how our robot system was tested.<br><br>
        </div>
        <div style="text-align:left;">        
                <pre><code>
                # genereic code</code></pre>
            
            
            <h4 style="text-align: left;text-indent: 0.8cm">User Interface: </h4>
            <p style="text-align: left;padding: 0px 30px;"></p>
            
            
      </div>
      <div style="text-align: center">
        <img class="img-rounded" src="" alt="Generic placeholder image" style="width:30%;">
        <img class="img-rounded" src="" alt="Generic placeholder image" style="width:30%;">
    </div> -->
      
      
            

    <hr id="results">

      <div style="text-align:center;">
              <h2>Results</h2>
              <p style="text-align: left;padding: 0px 30px;"></p>

      </div>
    
    
      <hr id="future">

      <div style="text-align:center;">
              <h2>Future Works</h2>
              <p style="text-align: left;padding: 0px 30px;"> </p>
      </div>

      <hr id="conclusion">

      <div style="text-align:center;">
              <h2>Conclusion</h2>
      </div>

    <hr>

    <div style="font-size:18px; text-align: center">
      <h2>Parts List</h2>
      <ul style="text-align: left; text-indent: 10cm">
          <p>- Raspberry Pi 4 $35.00</p>
          <a href="https://www.adafruit.com/product/1601"><p>- Adafruit PiTFT $35.00</p></a>
          <a href="https://www.raspberrypi.org/products/camera-module-v2/"><p>- Raspberry Pi Camera Module V2 $25.00</p></a>
          <p>- Robot base with DC motors $25.00</p>
          <p>- LEDs, Resistors and Wires - Provided during the course</p>
      </ul>
      <h4 style="text-align: center;">Total: $95.00</h4>
  </div>

    

    <hr>
    
    <div class="row" style="text-align:center;">
      <h2>Work Distribution</h2>
      <div class="col-md-6" style="font-size:16px">
          <img class="img-rounded" src="https://crcaplan.github.io/ece5725_finalproject/" alt="Generic placeholder image" width="240" height="240">
          <h3>Tamzid Ahmed</h3>
          <p class="lead">ta326@cornell.edu<br>ECE '21</p>
          <div style="text-align:left">
            <li>some work
          </li></div>
      </div>
      <div class="col-md-6" style="font-size:16px">
          <img class="img-rounded" src="https://crcaplan.github.io/ece5725_finalproject/" alt="Generic placeholder image" width="240" height="240">
          <h3>Claire Caplan</h3>
          <p class="lead">crc236@cornell.edu<br>ECE '21</p>
          <div style="text-align:left">
                <li>
          </li></div>
      </div>
  </div>

      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="http://abyz.co.uk/rpi/pigpio/">Pigpio Library</a><br>
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a><br>
          <a href="http://creat-tabu.blogspot.com/2013/08/opencv-python-hand-gesture-recognition.html">Hand gesture computer vision tutorial</a><br>
          <a href="https://courses.ece.cornell.edu/ece5990/ECE5725_Spring2020_Projects/May_15_Demo/Air%20Painter/awt46_sc2524_Thursday-3/awt46_sc2524_Thursday/index.html">ECE 5725 Air Painter project</a><br>
          <a href="https://courses.ece.cornell.edu/ece5990/ECE5725_Fall2018_Projects/ty359_yw996_Final_Project/index.html">ECE 5725 Tracking Robotic Car project</a><br>

      </div>

    <hr>

      <div class="row" style="font-size:18px">
              <h2>Code Appendix</h2>
              
              <a href="https://github.com/JonathanNusantara/BallTrackingRobot">Github Repository</a><br><br>
              <pre><code>
              </code></pre>
      </div>

    </div><!-- /.container -->




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./ECE 5725_ Touchless Music Player_files/jquery.min.js.download"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="./ECE 5725_ Touchless Music Player_files/bootstrap.min.js.download"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  

</body></html>